# coding=utf8

from __future__ import unicode_literals

import logging
import os
import random

import cfbclient

from tracing import Statsd
from tracing.codec import ThriftCodec
from tracing.initializer import Initializer
from tracing.sampler import BaseSampler, AdaptiveSampler
from tracing.sender import Sender, DatagramSender, KafkaSender
from tracing.tracer import ZipkinTracer

LOG = logging.getLogger(__name__)

env = os.getenv


class ZhihuInitializer(Initializer):
    def __init__(self, unit_name=None, record_trace=True, **kwargs):
        super(ZhihuInitializer, self).__init__()
        app_name = kwargs.get('app_name', env('ZHIHU_APP_NAME'))
        unit_name = unit_name or env('ZAE_UNIT_NAME')
        if not env('ZAE_ENV'):
            LOG.info("Not running in Zhihu infrastructure")
            app_name = app_name or "stub-app"
            unit_name = unit_name or "stub-unit"

        config = cfbclient.connect('tracing')

        version = env('ZHIHU_APP_VERSION', "stub-version")

        self.statsd_host = kwargs.get('statsd_host', "status")
        self.statsd_port = kwargs.get('statsd_port', 8126)
        self.sample_rate = kwargs.get('sample_rate', None)
        self.kafka_hosts = kwargs.get('kafka_hosts', None)
        self.kafka_topic = kwargs.get('kafka_topic', None)

        self.initialized = False
        self._config = config
        self._tracer = None
        self.sender = None
        self.sampler = BaseSampler(0.001)

        self.app_name = app_name
        self.unit_name = unit_name
        self.version = version
        self.enable_agent = False
        self.record_trace = record_trace
        self.max_buf_span = 1000

    def initialize(self):
        Statsd.initialize(self.app_name, self.unit_name, self.statsd_host,
                          self.statsd_port)
        if not self.record_trace:
            LOG.info("Trace recording disabled")
            self.initialized = True
            return

        enable_agent = self._config.get('enable_zipkin_agent', False)
        host = env('NODE_NAME')
        codec = ThriftCodec()

        self.sender = Sender()
        if enable_agent and host:
            self.enable_agent = True
            codec = ThriftCodec(max_spans_per_msg=1)
            _sender = self.initialize_datagram_sender(
                host=host, port=9422, codec=codec)
            self.max_buf_span = 1
        else:
            _sender = self.initialize_kafka_sender(codec=codec)

        if _sender:
            self.sender = _sender

        sample_rate = self.sample_rate or self._config.get('sample_rate', 0.001)
        self.sampler = AdaptiveSampler(sample_rate=sample_rate,
                                       sample_count=100)
        self.initialized = True

    @property
    def tracer(self):
        if not self.initialized:
            self.initialize()

        if not self._tracer:
            self._tracer = ZipkinTracer(
                unit_name=self.unit_name,
                version=self.version,
                sampler=self.sampler,
                sender=self.sender,
                max_buf_span=self.max_buf_span)

        return self._tracer

    def initialize_datagram_sender(self, host, port, codec):
        LOG.info("Using Zipkin Agent at {}".format(host))
        sndbuf = self._config.get('udp_send_buffer', None)
        if sndbuf:
            return DatagramSender(host, port, codec, sndbuf)
        else:
            return DatagramSender(host, port, codec)

    def initialize_kafka_sender(self, codec):
        kafka_hosts = self.kafka_hosts
        kafka_topic = self.kafka_topic
        if not kafka_hosts:
            kafka_clusters = self._config.get('kafka_clusters', None)
            if kafka_clusters:
                cluster = random.choice(kafka_clusters.keys())
                kafka_hosts = kafka_clusters[cluster]
                LOG.info("Using Kafka cluster {}".format(cluster))
            else:
                kafka_hosts = self._config.get('kafka_hosts', None)
        if kafka_hosts:
            LOG.info("Using Kafka hosts {}".format(kafka_hosts))
            kafka_topic = kafka_topic or self._config.get(
                'kafka_topic', "halo.msg.trace")
            try:
                return KafkaSender(kafka_hosts, kafka_topic, codec)
            except:
                LOG.error("Kafka sender initialization failed")
                return
        else:
            LOG.warning("No Kafka host found")
            return
